{"cells":[{"cell_type":"code","execution_count":null,"id":"33b675fd","metadata":{"id":"33b675fd"},"outputs":[],"source":["# !pip install scanpy\n","import os\n","import numpy as np\n","import pandas as pd\n","import scanpy as sc\n","import time\n","from scipy.stats import pearsonr\n","#\n","#more 10x datasets \n","#https://support.10xgenomics.com/single-cell-multiome-atac-gex/datasets/\n","\n","\n","#switch to keras for custom ae\n","#https://blog.keras.io/building-autoencoders-in-keras.html\n","#merging nerual networks\n","#https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from tensorflow.keras import backend as K\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n"]},{"cell_type":"code","execution_count":null,"id":"4ba1ab84","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ba1ab84","executionInfo":{"status":"ok","timestamp":1646848010165,"user_tz":480,"elapsed":1674,"user":{"displayName":"EMILY MACIEJEWSKI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06440088281541473321"}},"outputId":"9fa7a8c5-9e1c-4c69-e607-1b9c5edbc42f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["print(tf.test.gpu_device_name())"]},{"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#make a shortcut to emily's shared drive folder in your drive so you can access the data at\n","import os\n","os.listdir('/content/drive/My Drive/methyl_impute')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FmhHyvpd9Qj1","executionInfo":{"status":"ok","timestamp":1646848010996,"user_tz":480,"elapsed":836,"user":{"displayName":"EMILY MACIEJEWSKI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06440088281541473321"}},"outputId":"0d5eb2bf-83bd-47b4-b96c-a6c035d052b8"},"id":"FmhHyvpd9Qj1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["['Peek_data.ipynb',\n"," 'Project Proposal Brainstorming.gdoc',\n"," 'VAE_impute (vanilla) (custom dropout).ipynb',\n"," 'adult_cortex_CG-CH_OLDCOPY.h5ad',\n"," 'adult_cortex_CG_CH.h5ad',\n"," 'cg_counts.parq',\n"," 'cg_covs.parq',\n"," 'PredictionModel.ipynb',\n"," 'tf_multiclass_prediction.ipynb',\n"," 'classifier_results.gslides',\n"," 'Presentation.gslides',\n"," 'VAE_impute (vanilla).ipynb',\n"," 'VAE_impute (variational).ipynb']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"id":"83451993","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83451993","executionInfo":{"status":"ok","timestamp":1646848025465,"user_tz":480,"elapsed":9190,"user":{"displayName":"EMILY MACIEJEWSKI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06440088281541473321"}},"outputId":"1d78aa22-a2e8-4f8a-bb34-3c50c309a938"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["AnnData object with n_obs × n_vars = 11945 × 44772\n","    obs: 'sample', 'L1', 'L2', 'L3', 'true_batch', 'age', 'age_groups', 'leiden'\n","    var: 'batch'\n","    uns: 'L2_colors', 'L3_colors', 'leiden', 'neighbors', 'pca', 'umap'\n","    obsm: 'X_pca', 'X_umap'\n","    varm: 'PCs'\n","    obsp: 'connectivities', 'distances'"]},"metadata":{},"execution_count":4}],"source":["adata=sc.read_h5ad('/content/drive/My Drive/methyl_impute/adult_cortex_CG_CH.h5ad')\n","adata"]},{"cell_type":"code","execution_count":null,"id":"f04f44c7","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"f04f44c7","outputId":"fb3e1d7b-b617-4adc-d646-147334dd27df"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-d912db8d7927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#collect top marker genes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_genes_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'L3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_genes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# sc.pl.rank_genes_groups(adata, sharey=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmarkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scanpy/tools/_rank_genes_groups.py\u001b[0m in \u001b[0;36mrank_genes_groups\u001b[0;34m(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     test_obj.compute_statistics(\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_genes_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankby_abs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtie_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scanpy/tools/_rank_genes_groups.py\u001b[0m in \u001b[0;36mcompute_statistics\u001b[0;34m(self, method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mn_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_test_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m             \u001b[0mgroup_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scanpy/tools/_rank_genes_groups.py\u001b[0m in \u001b[0;36mt_test\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0mstd2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_rest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                     \u001b[0mnobs2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mns_rest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                     \u001b[0mequal_var\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Welch's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                 )\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mttest_ind_from_stats\u001b[0;34m(mean1, std1, nobs1, mean2, std2, nobs2, equal_var)\u001b[0m\n\u001b[1;32m   5135\u001b[0m                                              std2**2, nobs2)\n\u001b[1;32m   5136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5137\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ttest_ind_from_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTtest_indResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m_ttest_ind_from_stats\u001b[0;34m(mean1, mean2, denom, df)\u001b[0m\n\u001b[1;32m   5000\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5001\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5002\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ttest_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5004\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m_ttest_finish\u001b[0;34m(df, t)\u001b[0m\n\u001b[1;32m   4988\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ttest_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4989\u001b[0m     \u001b[0;34m\"\"\"Common code between all 3 t-test functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4990\u001b[0;31m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# use np.abs to get upper tail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4991\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4992\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36msf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m             \u001b[0mgoodargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margsreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1919\u001b[0;31m             \u001b[0mplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgoodargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_sf\u001b[0;34m(self, x, df)\u001b[0m\n\u001b[1;32m   5761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5763\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdtr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5765\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#collect top marker genes\n","\n","sc.tl.rank_genes_groups(adata, 'L3',n_genes=20)\n","# sc.pl.rank_genes_groups(adata, sharey=False)\n","markers=[]\n","for i in range(27):\n","    for j in range(20):\n","        if adata.uns['rank_genes_groups']['names'][j][i] not in markers:\n","            markers.append(adata.uns['rank_genes_groups']['names'][j][i])\n","\"\"\"adata2=adata[:,markers]\n","sc.pp.scale(adata2)\n","sc.pl.heatmap(adata2, markers, groupby='L3',vmax=1,vmin=-1)\"\"\""]},{"cell_type":"code","execution_count":null,"id":"ad7d7fb3","metadata":{"id":"ad7d7fb3"},"outputs":[],"source":["adata=adata[:,markers]\n","adata"]},{"cell_type":"code","execution_count":null,"id":"114f92a6","metadata":{"id":"114f92a6"},"outputs":[],"source":["#data matrix, X\n","X=np.array(adata.X)\n","print(X.shape)"]},{"cell_type":"code","source":["print(X.shape[1])"],"metadata":{"id":"kUzFbIh8-EDB"},"id":"kUzFbIh8-EDB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VAE:\n","  def __init__(self, input_shape,batch_size=256,optimizer=keras.optimizers.Adam(learning_rate=.001),epochs=50,\n","               recon_loss_function=tf.keras.losses.MeanSquaredError(),callback=tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)):\n","    # self.mu=layers.Dense(32,name='mu')\n","    # self.sigma=layers.Dense(32,name='sigma')\n","    self.mu = None\n","    self.sigma = None\n","\n","    self.input_shape=input_shape\n","    self.batch_size=batch_size\n","    self.n_epochs=epochs\n","    self.optimizer=optimizer\n","    self.recon_loss_function=recon_loss_function\n","    self.callback=callback\n","    # self.model=self.generate_model_architecture()\n","    # self.model.compile(optimizer=optimizer,loss=self.vae_loss)\n","    self.encoder=self.generate_encoder()\n","    self.encoder.compile(optimizer=optimizer,loss=self.vae_loss)\n","    self.sampler=self.perform_sampling()\n","    # self.sampler.compile(optimizer=optimizer,loss=self.vae_loss)\n","    self.decoder=self.generate_decoder()\n","    self.decoder.compile(optimizer=optimizer,loss=self.vae_loss)\n","    self.kappa=1\n","\n","  def vae_loss(self, y_true, y_pred):\n","    recon = self.recon_loss_function(y_true, y_pred)\n","    kl = K.mean(0.5*K.sum(K.exp(self.sigma) + K.square(self.mu) - 1. - self.sigma, axis=1))\n","    return 200*recon + self.kappa*kl\n","\n","  def sample_z(self, args):\n","    vae_mu, vae_sigma = args\n","    eps = K.random_normal(shape=(K.shape(vae_mu)[0], K.shape(vae_mu)[1]), mean=0., stddev=1., seed=42)\n","    return vae_mu + K.exp(vae_sigma/2)*eps\n","\n","  def kl_loss(self):\n","    return K.mean(0.5*K.sum(K.exp(self.sigma) + K.square(self.mu) - 1. - self.sigma, axis=1))\n","\n","  def generate_encoder(self):\n","    mC_input=keras.Input(shape=(self.input_shape,),name='mC_input')\n","    dense1=layers.Dense(128,activation='relu', name='dense1')(mC_input)\n","    dense2=layers.Dense(64,activation='relu', name='dense2')(dense1)\n","    vae_mu=layers.Dense(32,activation='linear')(dense2)\n","    vae_sigma=layers.Dense(32,activation='linear')(dense2)\n","\n","    return Model(mC_input, (vae_mu, vae_sigma), name='encoder')\n","\n","  def perform_sampling(self):\n","    vae_mu = keras.Input(shape=(32,))\n","    vae_sigma = keras.Input(shape=(32,))\n","    out=layers.Lambda(self.sample_z)([vae_mu, vae_sigma])\n","    return Model([vae_mu, vae_sigma], out, name='sampler')\n","\n","  def generate_decoder(self):\n","    input_latent = keras.Input(shape=(32,))\n","    out_pred=layers.Dense(self.input_shape,activation='linear',name='out_pred')(input_latent)\n","    return Model(input_latent, out_pred, name='decoder')\n","\n","  \"\"\"def generate_model_architecture(self):\n","    mC_input=keras.Input(shape=(self.input_shape,),name='mC_input')\n","    dense1=layers.Dense(128,activation='relu', name='dense1')(mC_input)\n","    dense2=layers.Dense(64,activation='relu', name='dense2')(dense1)\n","    self.mu=self.mu(dense2)\n","    self.sigma=self.sigma(dense2)\n","    latent=layers.Lambda(self.sample_z, output_shape=(32,), name='latent')([self.mu, self.sigma])\n","    # latent=layers.Dense(32,activation='relu', name='latent')(dense2)\n","    out_pred=layers.Dense(self.input_shape,activation='linear',name='out_pred')(latent)\n","\n","    return Model(mC_input,out_pred)\"\"\"\n","\n","\n","  def train_vae(self,train_dataset,test_dataset):\n","    train_acc_metric = keras.metrics.MeanSquaredError()\n","    test_acc_metric = keras.metrics.MeanSquaredError()\n","\n","    epochs = self.n_epochs\n","    for epoch in range(epochs):\n","        print(\"\\nStart of epoch %d\" % (epoch,))\n","        print(self.kappa)\n","        start_time = time.time()\n","\n","        # Iterate over the batches of the dataset.\n","        for step, (x_batch_train) in enumerate(train_dataset):\n","            with tf.GradientTape() as encoder_tape, tf.GradientTape() as decoder_tape:\n","                self.mu, self.sigma = self.encoder(x_batch_train, training=True)\n","                latent = self.sampler([self.mu, self.sigma])\n","                logits=self.decoder(latent, training=True)\n","                # logits = self.model(x_batch_train, training=True)\n","                loss_value = self.vae_loss(x_batch_train, logits)\n","                # print(loss_value)\n","            encoder_grads = encoder_tape.gradient(loss_value, self.encoder.trainable_weights)\n","            decoder_grads = decoder_tape.gradient(loss_value, self.decoder.trainable_weights)\n","            self.optimizer.apply_gradients(zip(encoder_grads, self.encoder.trainable_weights))\n","            self.optimizer.apply_gradients(zip(decoder_grads, self.decoder.trainable_weights))\n","            # grads = tape.gradient(loss_value, self.model.trainable_weights)\n","            # self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n","\n","            # Update training metric.\n","            train_acc_metric.update_state(x_batch_train, logits)\n","\n","            # Log every 31 batches.\n","            if step % 31 == 0:\n","                print(\n","                    \"Training loss (for one batch) at step %d: %.4f\"\n","                    % (step, float(loss_value))\n","                )\n","                #print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n","\n","        # Display metrics at the end of each epoch.\n","        train_acc = train_acc_metric.result()\n","        print(\"Reconstruction Training acc over epoch: %.4f\" % (float(train_acc),))\n","        print(\"KL Divergence: %.10f\" % (float(self.kl_loss())))\n","\n","        # Reset training metrics at the end of each epoch\n","        train_acc_metric.reset_states()\n","\n","        # Run a validation loop at the end of each epoch.\n","        for x_batch_test in test_dataset:\n","            self.mu, self.sigma = self.encoder(x_batch_test, training=False)\n","            latent = self.sampler([self.mu, self.sigma])\n","            test_logits = self.decoder(latent, training=False)\n","            # test_logits = self.model(x_batch_test, training=False)\n","            # Update val metrics\n","            test_acc_metric.update_state(x_batch_test, test_logits)\n","        test_acc = test_acc_metric.result()\n","        test_acc_metric.reset_states()\n","        print(\"Validation acc: %.4f\" % (float(test_acc),))\n","        #print(\"Time taken: %.2fs\" % (time.time() - start_time))\n","\n","        if self.kappa < 0.95:\n","            self.kappa += 0.25\n","\n","  def predict(self,X):\n","    self.mu, self.sigma = self.encoder.predict(X)\n","    latent = self.sampler([self.mu, self.sigma])\n","    return self.decoder.predict(latent)\n","\n","  def model_summary(self):\n","    print(self.model.summary())\n","\n","  def visualize_model(self):\n","    #dunno how to make this show from the function lol\n","    keras.utils.plot_model(self.model, show_shapes=True, show_layer_names=True)\n","\n","  def correlation_accuracy(self, real_data):\n","    reconstructed_data = self.predict(real_data)\n","    corrs = 0\n","    for i in range(len(reconstructed_data)):\n","        corrs += pearsonr(reconstructed_data[i], real_data[i])[0]\n","\n","    print(corrs/len(reconstructed_data))\n","\n","  def mse_error(self, real_data):\n","    reconstructed_data = self.predict(real_data)\n","    mse = 0\n","    for i in range(len(reconstructed_data)):\n","        mse += mean_squared_error(reconstructed_data[i], real_data[i])\n","\n","    print(mse/len(reconstructed_data))\n","\n","\n"],"metadata":{"id":"hv7PmI4s6TpB"},"id":"hv7PmI4s6TpB","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"d187df77","metadata":{"id":"d187df77"},"outputs":[],"source":["# X_train, X_test = train_test_split(X, test_size=0.33, random_state=42,shuffle=True)\n","X_train, X_test = train_test_split(np.array(adata.X), test_size=0.33, random_state=42,shuffle=True)"]},{"cell_type":"code","execution_count":null,"id":"408d4bc6","metadata":{"id":"408d4bc6"},"outputs":[],"source":["vae=VAE(X_train.shape[1])"]},{"cell_type":"code","execution_count":null,"id":"00d6a051","metadata":{"id":"00d6a051"},"outputs":[],"source":["batch_size=256\n","\n","train_dataset=tf.data.Dataset.from_tensor_slices(X_train)\n","train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n","test_dataset = test_dataset.batch(batch_size)"]},{"cell_type":"code","execution_count":null,"id":"a8083272","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8083272","executionInfo":{"status":"ok","timestamp":1646848031247,"user_tz":480,"elapsed":4,"user":{"displayName":"EMILY MACIEJEWSKI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06440088281541473321"}},"outputId":"1ff3a5b5-0125-4c21-a201-e33fe36144e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["31.26171875"]},"metadata":{},"execution_count":9}],"source":["len(X_train)/batch_size"]},{"cell_type":"code","source":["vae.train_vae(train_dataset,test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMoN2Z8zPQl2","executionInfo":{"status":"ok","timestamp":1646848272132,"user_tz":480,"elapsed":238319,"user":{"displayName":"EMILY MACIEJEWSKI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06440088281541473321"}},"outputId":"e71da13e-0ab5-47e1-e6f4-c4877279e37f"},"id":"sMoN2Z8zPQl2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Start of epoch 0\n","1\n","Training loss (for one batch) at step 0: 37.9012\n","Training loss (for one batch) at step 31: 30.5923\n","Reconstruction Training acc over epoch: 0.1168\n","KL Divergence: 15.2886524200\n","Validation acc: 0.0778\n","\n","Start of epoch 1\n","1\n","Training loss (for one batch) at step 0: 29.0215\n","Training loss (for one batch) at step 31: 12.9607\n","Reconstruction Training acc over epoch: 0.0565\n","KL Divergence: 7.2303476334\n","Validation acc: 0.0271\n","\n","Start of epoch 2\n","1\n","Training loss (for one batch) at step 0: 12.4957\n","Training loss (for one batch) at step 31: 9.4576\n","Reconstruction Training acc over epoch: 0.0248\n","KL Divergence: 4.8570814133\n","Validation acc: 0.0238\n","\n","Start of epoch 3\n","1\n","Training loss (for one batch) at step 0: 9.8642\n","Training loss (for one batch) at step 31: 8.9348\n","Reconstruction Training acc over epoch: 0.0225\n","KL Divergence: 4.1816916466\n","Validation acc: 0.0225\n","\n","Start of epoch 4\n","1\n","Training loss (for one batch) at step 0: 8.4782\n","Training loss (for one batch) at step 31: 7.9475\n","Reconstruction Training acc over epoch: 0.0217\n","KL Divergence: 3.6728405952\n","Validation acc: 0.0212\n","\n","Start of epoch 5\n","1\n","Training loss (for one batch) at step 0: 7.8868\n","Training loss (for one batch) at step 31: 6.8322\n","Reconstruction Training acc over epoch: 0.0216\n","KL Divergence: 3.5404911041\n","Validation acc: 0.0213\n","\n","Start of epoch 6\n","1\n","Training loss (for one batch) at step 0: 7.6048\n","Training loss (for one batch) at step 31: 8.2473\n","Reconstruction Training acc over epoch: 0.0215\n","KL Divergence: 3.1116898060\n","Validation acc: 0.0211\n","\n","Start of epoch 7\n","1\n","Training loss (for one batch) at step 0: 7.6374\n","Training loss (for one batch) at step 31: 7.1612\n","Reconstruction Training acc over epoch: 0.0214\n","KL Divergence: 3.0845682621\n","Validation acc: 0.0208\n","\n","Start of epoch 8\n","1\n","Training loss (for one batch) at step 0: 7.4530\n","Training loss (for one batch) at step 31: 6.4322\n","Reconstruction Training acc over epoch: 0.0211\n","KL Divergence: 2.8721134663\n","Validation acc: 0.0209\n","\n","Start of epoch 9\n","1\n","Training loss (for one batch) at step 0: 6.7835\n","Training loss (for one batch) at step 31: 8.5340\n","Reconstruction Training acc over epoch: 0.0207\n","KL Divergence: 2.5740759373\n","Validation acc: 0.0217\n","\n","Start of epoch 10\n","1\n","Training loss (for one batch) at step 0: 7.1209\n","Training loss (for one batch) at step 31: 7.0343\n","Reconstruction Training acc over epoch: 0.0207\n","KL Divergence: 2.4698798656\n","Validation acc: 0.0209\n","\n","Start of epoch 11\n","1\n","Training loss (for one batch) at step 0: 6.9217\n","Training loss (for one batch) at step 31: 6.2243\n","Reconstruction Training acc over epoch: 0.0206\n","KL Divergence: 2.5138094425\n","Validation acc: 0.0195\n","\n","Start of epoch 12\n","1\n","Training loss (for one batch) at step 0: 6.4219\n","Training loss (for one batch) at step 31: 6.5714\n","Reconstruction Training acc over epoch: 0.0201\n","KL Divergence: 2.4130222797\n","Validation acc: 0.0192\n","\n","Start of epoch 13\n","1\n","Training loss (for one batch) at step 0: 6.4644\n","Training loss (for one batch) at step 31: 6.6921\n","Reconstruction Training acc over epoch: 0.0198\n","KL Divergence: 2.4327096939\n","Validation acc: 0.0191\n","\n","Start of epoch 14\n","1\n","Training loss (for one batch) at step 0: 6.0190\n","Training loss (for one batch) at step 31: 6.1634\n","Reconstruction Training acc over epoch: 0.0196\n","KL Divergence: 1.9809918404\n","Validation acc: 0.0190\n","\n","Start of epoch 15\n","1\n","Training loss (for one batch) at step 0: 6.1544\n","Training loss (for one batch) at step 31: 5.7475\n","Reconstruction Training acc over epoch: 0.0194\n","KL Divergence: 2.2960913181\n","Validation acc: 0.0194\n","\n","Start of epoch 16\n","1\n","Training loss (for one batch) at step 0: 6.0767\n","Training loss (for one batch) at step 31: 5.7496\n","Reconstruction Training acc over epoch: 0.0188\n","KL Divergence: 1.9816083908\n","Validation acc: 0.0187\n","\n","Start of epoch 17\n","1\n","Training loss (for one batch) at step 0: 5.8634\n","Training loss (for one batch) at step 31: 5.3162\n","Reconstruction Training acc over epoch: 0.0185\n","KL Divergence: 1.9777239561\n","Validation acc: 0.0189\n","\n","Start of epoch 18\n","1\n","Training loss (for one batch) at step 0: 5.4086\n","Training loss (for one batch) at step 31: 5.5019\n","Reconstruction Training acc over epoch: 0.0182\n","KL Divergence: 1.7887632847\n","Validation acc: 0.0183\n","\n","Start of epoch 19\n","1\n","Training loss (for one batch) at step 0: 5.2104\n","Training loss (for one batch) at step 31: 5.1869\n","Reconstruction Training acc over epoch: 0.0179\n","KL Divergence: 1.7586110830\n","Validation acc: 0.0173\n","\n","Start of epoch 20\n","1\n","Training loss (for one batch) at step 0: 5.3143\n","Training loss (for one batch) at step 31: 5.0446\n","Reconstruction Training acc over epoch: 0.0172\n","KL Divergence: 1.6897343397\n","Validation acc: 0.0179\n","\n","Start of epoch 21\n","1\n","Training loss (for one batch) at step 0: 5.2096\n","Training loss (for one batch) at step 31: 4.9702\n","Reconstruction Training acc over epoch: 0.0169\n","KL Divergence: 1.7298915386\n","Validation acc: 0.0172\n","\n","Start of epoch 22\n","1\n","Training loss (for one batch) at step 0: 4.7429\n","Training loss (for one batch) at step 31: 4.7469\n","Reconstruction Training acc over epoch: 0.0164\n","KL Divergence: 1.5124670267\n","Validation acc: 0.0167\n","\n","Start of epoch 23\n","1\n","Training loss (for one batch) at step 0: 4.9213\n","Training loss (for one batch) at step 31: 4.3742\n","Reconstruction Training acc over epoch: 0.0160\n","KL Divergence: 1.4452507496\n","Validation acc: 0.0154\n","\n","Start of epoch 24\n","1\n","Training loss (for one batch) at step 0: 4.4444\n","Training loss (for one batch) at step 31: 4.5239\n","Reconstruction Training acc over epoch: 0.0155\n","KL Divergence: 1.3283715248\n","Validation acc: 0.0156\n","\n","Start of epoch 25\n","1\n","Training loss (for one batch) at step 0: 4.1139\n","Training loss (for one batch) at step 31: 3.7960\n","Reconstruction Training acc over epoch: 0.0152\n","KL Divergence: 1.2612133026\n","Validation acc: 0.0156\n","\n","Start of epoch 26\n","1\n","Training loss (for one batch) at step 0: 4.4083\n","Training loss (for one batch) at step 31: 4.1081\n","Reconstruction Training acc over epoch: 0.0149\n","KL Divergence: 1.2413984537\n","Validation acc: 0.0147\n","\n","Start of epoch 27\n","1\n","Training loss (for one batch) at step 0: 4.2463\n","Training loss (for one batch) at step 31: 3.9873\n","Reconstruction Training acc over epoch: 0.0142\n","KL Divergence: 1.0970817804\n","Validation acc: 0.0146\n","\n","Start of epoch 28\n","1\n","Training loss (for one batch) at step 0: 4.0156\n","Training loss (for one batch) at step 31: 3.6832\n","Reconstruction Training acc over epoch: 0.0139\n","KL Divergence: 0.9777818322\n","Validation acc: 0.0134\n","\n","Start of epoch 29\n","1\n","Training loss (for one batch) at step 0: 3.7597\n","Training loss (for one batch) at step 31: 3.7085\n","Reconstruction Training acc over epoch: 0.0133\n","KL Divergence: 1.0001691580\n","Validation acc: 0.0133\n","\n","Start of epoch 30\n","1\n","Training loss (for one batch) at step 0: 3.6859\n","Training loss (for one batch) at step 31: 3.2246\n","Reconstruction Training acc over epoch: 0.0130\n","KL Divergence: 0.9129608870\n","Validation acc: 0.0128\n","\n","Start of epoch 31\n","1\n","Training loss (for one batch) at step 0: 3.4966\n","Training loss (for one batch) at step 31: 3.5360\n","Reconstruction Training acc over epoch: 0.0128\n","KL Divergence: 0.8614503145\n","Validation acc: 0.0127\n","\n","Start of epoch 32\n","1\n","Training loss (for one batch) at step 0: 3.3817\n","Training loss (for one batch) at step 31: 3.1501\n","Reconstruction Training acc over epoch: 0.0124\n","KL Divergence: 0.8713825345\n","Validation acc: 0.0118\n","\n","Start of epoch 33\n","1\n","Training loss (for one batch) at step 0: 3.3546\n","Training loss (for one batch) at step 31: 2.9052\n","Reconstruction Training acc over epoch: 0.0120\n","KL Divergence: 0.7004118562\n","Validation acc: 0.0122\n","\n","Start of epoch 34\n","1\n","Training loss (for one batch) at step 0: 3.1492\n","Training loss (for one batch) at step 31: 3.0891\n","Reconstruction Training acc over epoch: 0.0118\n","KL Divergence: 0.7150596380\n","Validation acc: 0.0117\n","\n","Start of epoch 35\n","1\n","Training loss (for one batch) at step 0: 2.9787\n","Training loss (for one batch) at step 31: 2.9127\n","Reconstruction Training acc over epoch: 0.0116\n","KL Divergence: 0.6556169987\n","Validation acc: 0.0111\n","\n","Start of epoch 36\n","1\n","Training loss (for one batch) at step 0: 2.8637\n","Training loss (for one batch) at step 31: 2.6384\n","Reconstruction Training acc over epoch: 0.0112\n","KL Divergence: 0.6234934330\n","Validation acc: 0.0115\n","\n","Start of epoch 37\n","1\n","Training loss (for one batch) at step 0: 2.7751\n","Training loss (for one batch) at step 31: 2.5753\n","Reconstruction Training acc over epoch: 0.0110\n","KL Divergence: 0.5257837772\n","Validation acc: 0.0113\n","\n","Start of epoch 38\n","1\n","Training loss (for one batch) at step 0: 2.7690\n","Training loss (for one batch) at step 31: 2.5263\n","Reconstruction Training acc over epoch: 0.0109\n","KL Divergence: 0.4997970164\n","Validation acc: 0.0107\n","\n","Start of epoch 39\n","1\n","Training loss (for one batch) at step 0: 2.6404\n","Training loss (for one batch) at step 31: 2.4576\n","Reconstruction Training acc over epoch: 0.0107\n","KL Divergence: 0.4363947511\n","Validation acc: 0.0106\n","\n","Start of epoch 40\n","1\n","Training loss (for one batch) at step 0: 2.6278\n","Training loss (for one batch) at step 31: 2.6606\n","Reconstruction Training acc over epoch: 0.0105\n","KL Divergence: 0.4140859842\n","Validation acc: 0.0103\n","\n","Start of epoch 41\n","1\n","Training loss (for one batch) at step 0: 2.5147\n","Training loss (for one batch) at step 31: 2.4271\n","Reconstruction Training acc over epoch: 0.0103\n","KL Divergence: 0.3431077003\n","Validation acc: 0.0105\n","\n","Start of epoch 42\n","1\n","Training loss (for one batch) at step 0: 2.4199\n","Training loss (for one batch) at step 31: 2.2830\n","Reconstruction Training acc over epoch: 0.0102\n","KL Divergence: 0.2904265225\n","Validation acc: 0.0102\n","\n","Start of epoch 43\n","1\n","Training loss (for one batch) at step 0: 2.2687\n","Training loss (for one batch) at step 31: 2.2110\n","Reconstruction Training acc over epoch: 0.0100\n","KL Divergence: 0.2614806890\n","Validation acc: 0.0099\n","\n","Start of epoch 44\n","1\n","Training loss (for one batch) at step 0: 2.1887\n","Training loss (for one batch) at step 31: 2.1751\n","Reconstruction Training acc over epoch: 0.0099\n","KL Divergence: 0.2003674507\n","Validation acc: 0.0099\n","\n","Start of epoch 45\n","1\n","Training loss (for one batch) at step 0: 2.1934\n","Training loss (for one batch) at step 31: 2.0540\n","Reconstruction Training acc over epoch: 0.0097\n","KL Divergence: 0.1647707373\n","Validation acc: 0.0096\n","\n","Start of epoch 46\n","1\n","Training loss (for one batch) at step 0: 2.1385\n","Training loss (for one batch) at step 31: 2.0705\n","Reconstruction Training acc over epoch: 0.0095\n","KL Divergence: 0.1375960559\n","Validation acc: 0.0094\n","\n","Start of epoch 47\n","1\n","Training loss (for one batch) at step 0: 1.9789\n","Training loss (for one batch) at step 31: 1.8111\n","Reconstruction Training acc over epoch: 0.0093\n","KL Divergence: 0.0880219117\n","Validation acc: 0.0092\n","\n","Start of epoch 48\n","1\n","Training loss (for one batch) at step 0: 1.8934\n","Training loss (for one batch) at step 31: 1.9093\n","Reconstruction Training acc over epoch: 0.0091\n","KL Divergence: 0.0641936436\n","Validation acc: 0.0090\n","\n","Start of epoch 49\n","1\n","Training loss (for one batch) at step 0: 1.8336\n","Training loss (for one batch) at step 31: 1.7648\n","Reconstruction Training acc over epoch: 0.0088\n","KL Divergence: 0.0384907797\n","Validation acc: 0.0088\n"]}]},{"cell_type":"code","source":["vae.predict(X_train)"],"metadata":{"id":"m9nGo9vLRo6Y"},"id":"m9nGo9vLRo6Y","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"f4855304","metadata":{"id":"f4855304","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646848282634,"user_tz":480,"elapsed":10506,"user":{"displayName":"EMILY MACIEJEWSKI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06440088281541473321"}},"outputId":"2e286650-f75c-4900-c40a-a528561c6cf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.9663105203861073\n","0.008784314968768754\n"]}],"source":["# vae.correlation_accuracy(X_train)\n","vae.correlation_accuracy(X_test)\n","# vae.mse_error(X_train)\n","vae.mse_error(X_test)"]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:tf-gpu] *","language":"python","name":"conda-env-tf-gpu-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"VAE_impute (variational).ipynb","provenance":[{"file_id":"1UKfEK6MV2zMjFjIa-uCFK4ph_gTL3go-","timestamp":1646172568867}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}